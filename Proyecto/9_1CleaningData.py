import re
format_pat = re.compile(
    r"(?P<host>[\d\.]+)\s"
    r"(?P<identity>\S*)\s"
    r"(?P<user>\S*)\s"
    r"\[(?P<time>.*?)\]\s"
    r'"(?P<request>.*?)"\s'
    r"(?P<status>\d+)\s"
    r"(?P<bytes>\S*)\s"
    r'"(?P<referer>.*?)"\s'
    r'"(?P<user_agent>.*?)"\s*'
)

logPath = "C:/Users/ediso/Desktop/Python Projects/Data Science/Curso DataScience/DataScience-Python3-Resources/access_log.txt"

URLCounts = {}

with open(logPath, "r") as f:
    for line in (l.rstrip() for l in f):
        match= format_pat.match(line)
        if match:
            access = match.groupdict()
            request = access['request']
            fields = request.split()
            # (action, URL, protocol) = request.split()
            if(len(fields)==3):
                URL=fields[1]
                if URL in URLCounts:
                    URLCounts[URL] = URLCounts[URL] + 1
                else:
                    URLCounts[URL] = 1

results = sorted(URLCounts, key=lambda i: int(URLCounts[i]), reverse=True)

for result in results[:20]:
    print(result + ": " + str(URLCounts[result]))


print('')
print('///////// Filtrado GET //////////////////////////////////////////////////////////////////////////////////////')
print('')

with open(logPath, "r") as f:
    for line in (l.rstrip() for l in f):
        match= format_pat.match(line)
        if match:
            access = match.groupdict()
            request = access['request']
            fields = request.split()
            if(len(fields)==3):
                (action, URL, protocol)=fields
                if (action =='GET'):
                    if URL in URLCounts:
                        URLCounts[URL] = URLCounts[URL] + 1
                    else:
                        URLCounts[URL] = 1

results = sorted(URLCounts, key=lambda i: int(URLCounts[i]), reverse=True)

for result in results[:20]:
    print(result + ": " + str(URLCounts[result]))


print('')
print('///////// CHECK IF THEY ARE HUMANS by browser visited //////////////////////////////////////////////////////////////////////////////////////')
print('')

UserAgents={}

with open(logPath, "r") as f:
    for line in (l.rstrip() for l in f):
        match= format_pat.match(line)
        if match:
            access = match.groupdict()
            agent = access['user_agent']
            if agent in UserAgents:
                UserAgents[agent]=UserAgents[agent]+1
            else:
                UserAgents[agent]=1
                
results = sorted(UserAgents, key=lambda i: int(UserAgents[i]), reverse=True)

for result in results[:20]:
    print(result + ": " + str(UserAgents[result]))


print('')
print('///////// ELIMINAR TODO LO QUE NOSEA HUMANO BOTS ETC //////////////////////////////////////////////////////////////////////////////////////')
print('')

URLCounts = {}

with open(logPath, "r") as f:
    for line in (l.rstrip() for l in f):
        match= format_pat.match(line)
        if match:
            access = match.groupdict()
            agent = access['user_agent']
            if (not('bot' in agent or 'spider' in agent or
                    'Bot' in agent or 'Spider' in agent or
                    'W3 Total Cache' in agent or '-' in agent)):

                request = access['request']
                fields = request.split()
                if(len(fields)==3):
                    (action, URL, protocol)=fields
                    if (action =='GET'):
                        if URL in URLCounts:
                            URLCounts[URL] = URLCounts[URL] + 1
                        else:
                            URLCounts[URL] = 1

results = sorted(URLCounts, key=lambda i: int(URLCounts[i]), reverse=True)

for result in results[:20]:
    print(result + ": " + str(URLCounts[result]))


print('')
print('///////// ELIMINAR TODO LO QUE NO SEA PAGINAS WEB //////////////////////////////////////////////////////////////////////////////////////')
print('')

URLCounts = {}

with open(logPath, "r") as f:
    for line in (l.rstrip() for l in f):
        match= format_pat.match(line)
        if match:
            access = match.groupdict()
            agent = access['user_agent']
            if (not('bot' in agent or 'spider' in agent or
                    'Bot' in agent or 'Spider' in agent or
                    'W3 Total Cache' in agent or '-' in agent)):

                request = access['request']
                fields = request.split()
                if(len(fields)==3):
                    (action, URL, protocol)=fields
                    if (URL.endswith("/")):
                        if (action =='GET'):
                            if URL in URLCounts:
                                URLCounts[URL] = URLCounts[URL] + 1
                            else:
                                URLCounts[URL] = 1

results = sorted(URLCounts, key=lambda i: int(URLCounts[i]), reverse=True)

for result in results[:20]:
    print(result + ": " + str(URLCounts[result]))


